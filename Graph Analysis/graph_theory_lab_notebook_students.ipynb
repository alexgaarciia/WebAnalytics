{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXyjStDAxxBN"
      },
      "source": [
        "<img src=\"https://www.uc3m.es/ss/Satellite?blobcol=urldata&blobkey=id&blobtable=MungoBlobs&blobwhere=1371573952659\">\n",
        "\n",
        "# WEB ANALYTICS. Data Science and Engineering Degree (1st semester. 4th course)\n",
        "\n",
        "# *Graph Theory Lab*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Members (Group 17)\n",
        "* Ángela María Durán Pinto: 100472766\n",
        "* Alejandro Leonardo García Navarro: 100472710\n",
        "* Melania Guerra Ulloa: 100457522\n",
        "* Francisco Javier Molina Tirado: 100456560"
      ],
      "metadata": {
        "id": "6Ihl6p-tq7Qm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JzTr04lulfL"
      },
      "source": [
        "# 0. Lab Preparation\n",
        "\n",
        "Students should prepare the lab by completing the following two tasks:\n",
        "\n",
        "\n",
        "\n",
        "1.   Studying and thus having celar the concepts explained in the theoretical classes.\n",
        "\n",
        "2.   Gain experience with the use of the [NetworkX Python Library](https://networkx.org/documentation/stable/reference/index.html). The different exercises to be solved during the lab will be mainly based on the utilization of functions offered by this library.\n",
        "\n",
        ">* [Here](https://networkx.org/nx-guides/content/tutorial.html) you can find a very basic tutorial. (Consider this tutorial, just as a starting point. To prepare the lab, it is expected that you go further than what is covered in this very simple tutorial)\n",
        "\n",
        "3. It is assumed students have experience in using Python notebooks. Either a local installation (e.g., local python installation + Jupyter) or a cloud-based solution (e.g., Google Colab). *We recommend the second option*.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpgqHXuevDFt"
      },
      "source": [
        "#1. Lab Introduction\n",
        "\n",
        "- In this lab we will implement different metrics and algorithms we have covered in the theoretical classes.\n",
        "\n",
        "- The lab will be done in groups of 2 people.\n",
        "\n",
        "- The lab defines a set of milestones the students must complete. Upon the completion of every milestone students should call the professor, who will check the correctness of the solution (*If the professor is busy, do not wait for them, move to the next milestone*).\n",
        "\n",
        "- **The final mark will be computed as function of the number of milestones successfully completed.**\n",
        "\n",
        "- **Each group should also share their lab notebook with the professor upon the finalization of the lab.**\n",
        "\n",
        "- In this lab we will use the [NetworkX Phython]( https://networkx.org/documentation/stable/reference/index.html) library for the analysis of graphs and networks. As indicated in the *Lab Preparation* section above, it is expected that students have gained experience in the use of the NetworkX library before starting the first session of the lab.\n",
        "\n",
        "- It is  recommended to use [Google Colab](https://colab.research.google.com/) to produce the Python notebook with the solution of the lab. Of course, if any student prefers using its local programming environment (e.g., jupyter) and python installation, they is  welcome to do so.\n",
        "\n",
        "- *Note that most of the milestones consists in the implementation of metrics or algorithms which are already implemented in NetworkX. Hence, before calling the professor for checking the correctness of a milestone, it is highly recommended that students compare the result obtained with their solution and the equivalent function of NetworkX. The results should match. For instance, if a milestone requires to implement the Betweenness Centrality metric, students can check if their implementation of this metric is correct by comparing it with the result offered by the [betweenness centrality](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.betweenness_centrality.html#networkx.algorithms.centrality.betweenness_centrality) from the NetworkX library.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNNnpecv1wbt"
      },
      "source": [
        "# MILESTONE 0\n",
        "\n",
        "a) Generate a directed graph with 5 nodes and 6 edges between those nodes.\n",
        "*We recommend you to use the functions add_nodes_from and add_edges_from*\n",
        "\n",
        "b) Plot the resulting graph. You can use the following code for that purpose:\n",
        "\n",
        "\n",
        "```\n",
        "# We assume the graph is created in the variable G\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "pos = nx.spring_layout(G)\n",
        "nx.draw_networkx(G, pos)\n",
        "plt.title(\"My first Graph\")\n",
        "plt.show()\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7VxAMM_F_QS"
      },
      "outputs": [],
      "source": [
        "# Milestone 0 solution questions a) and b)\n",
        "# A) Generate a directed graph with 5 nodes and 6 edges between those nodes\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a directed graph\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# Add nodes and directed edges between nodes\n",
        "G.add_nodes_from([1, 2, 3, 4, 5])\n",
        "G.add_edges_from([(1, 2), (2, 3), (3, 4), (4, 5), (5, 1), (2, 4)])\n",
        "\n",
        "\n",
        "# B) Plot the resulting graph\n",
        "pos = nx.spring_layout(G)\n",
        "nx.draw_networkx(G, pos)\n",
        "plt.title(\"My first Graph\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-gTZDJr397k"
      },
      "source": [
        "c) Generate an Erdös-Renyi graph with 10 nodes and a probability of creating an edge of 0.4 using the networkX's function ```erdos_renyi_graph```\n",
        "\n",
        "d) Plot the resulting graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BH5iq5ur5ghf"
      },
      "outputs": [],
      "source": [
        "# Milestone 0 solution questions c) and d)\n",
        "# C) Generate an Erdös-Renyi graph with 10 nodes and a probability of creating an edge of 0.4\n",
        "G_erdos = nx.erdos_renyi_graph(10, 0.4)\n",
        "\n",
        "# D) Plot the resulting graph\n",
        "pos = nx.spring_layout(G_erdos)\n",
        "nx.draw_networkx(G_erdos, pos)\n",
        "plt.title(\"Erdös-Renyi Graph with 10 Nodes and p=0.4\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgeVraGR56mL"
      },
      "source": [
        "e) Generate an undirected Barabasi-Albert graph with 10 nodes and each nodes creating 3 edges upon joining the graph using the networkX's function ```barabasi_albert_graph```\n",
        "\n",
        "f) Plot the resulting graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgoBMJSw6RH1"
      },
      "outputs": [],
      "source": [
        "# Milestone 0 solution questions e) and f)\n",
        "# E) Generate an undirected Barabasi-Albert graph with 10 nodes and each nodes creating 3 edges upon joining the graph\n",
        "G_barabasi = nx.barabasi_albert_graph(10, 3)\n",
        "\n",
        "# F) Plot the resulting graph\n",
        "pos = nx.spring_layout(G_barabasi)\n",
        "nx.draw_networkx(G_barabasi, pos)\n",
        "plt.title(\"Barabasi-Albert Graph with 10 Nodes and 3 Edges per Node\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piNC4QXL6n9i"
      },
      "source": [
        "g) Generate a directed Barabasi-Albert graph with 10 nodes using the networkX's function ```scale_free_graph```\n",
        "\n",
        "h) Plot the resulting graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6HZCK8K60iU"
      },
      "outputs": [],
      "source": [
        "# Milestone 0 solution questions g) and h)\n",
        "# G) Generate a directed Barabasi-Albert graph with 10 nodes\n",
        "G_barabasi_directed = nx.scale_free_graph(10)\n",
        "\n",
        "# H) Plot the resulting graph\n",
        "pos = nx.spring_layout(G_barabasi_directed)\n",
        "nx.draw_networkx(G_barabasi_directed, pos, arrows=True)\n",
        "plt.title(\"Directed Barabasi-Albert Graph with 10 Nodes\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUAdfXZK7Phv"
      },
      "source": [
        "i) Generate a small-world graph with 20 nodes, 4 edges per node and a replacement probability of 0.2 using the networkX's function ```newman_watts_strogatz_graph```\n",
        "\n",
        "j) Plot the resulting graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kC6TZ1K7suu"
      },
      "outputs": [],
      "source": [
        "# Milestone 0 solution questions i) and j)\n",
        "# I) Generate a small-world graph with 20 nodes, 4 edges per node and a replacement probability of 0.2\n",
        "G_newman = nx.newman_watts_strogatz_graph(20, 4, 0.2)\n",
        "\n",
        "# J) Plot the resulting graph\n",
        "pos = nx.spring_layout(G_newman)\n",
        "nx.draw_networkx(G_newman, pos)\n",
        "plt.title(\"Small-World Graph with 20 Nodes, 4 Edges per Node, Probability of 0.2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1AOlJCf8YI3"
      },
      "source": [
        "# MILESTONE 1\n",
        "\n",
        "a) Write the code to construct from scratch an **unidirected** random graph with 10 nodes using the Gilbert model, i.e., the probability of an edge existing between a pair of nodes is p. For this exercise use p = 0.4.\n",
        "\n",
        "- *Note that you cannot use any of the functions that automatically creates a random graph from NetworkX library.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBBhvRdd9Myr"
      },
      "outputs": [],
      "source": [
        "# Solution Milestone 1 question a)\n",
        "import random\n",
        "\n",
        "def undirected_gilbert(num_nodes, p):\n",
        "  # Create an empty undirected graph\n",
        "  G = nx.Graph()\n",
        "\n",
        "  # Add the specified number of nodes\n",
        "  G.add_nodes_from(range(num_nodes))\n",
        "\n",
        "  # For each pair of nodes add an edge with probability p\n",
        "  for i in range(num_nodes):\n",
        "    for j in range(i + 1, num_nodes):\n",
        "      if random.random() < p:\n",
        "        G.add_edge(i, j)\n",
        "\n",
        "  return G\n",
        "\n",
        "G = undirected_gilbert(10, 0.4)\n",
        "nx.draw(G, with_labels=True, node_color='salmon', node_size=500, font_size=10, font_color='black', pos=nx.spring_layout(G))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8deyPlJ29k6P"
      },
      "source": [
        "b) Write the code to construct from scratch a **directed** random graph with 10 nodes using the Gilbert model, i.e., the probability of an edge existing between a pair of nodes is p. For this exercise use p = 0.4.\n",
        "\n",
        "- *Note that you cannot use any of the functions that automatically creates a random graph from NetworkX library.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBRuxDFn9xEn"
      },
      "outputs": [],
      "source": [
        "# Solution Milestone 1 question b)\n",
        "def directed_gilbert(num_nodes, p):\n",
        "  # Create an empty directed graph\n",
        "  diG = nx.DiGraph()\n",
        "\n",
        "  # Add the specified number of edges\n",
        "  diG.add_nodes_from(range(num_nodes))\n",
        "\n",
        "  # Iterate through each pair of nodes to add directed edges\n",
        "  for i in range(num_nodes):\n",
        "    for j in range(num_nodes):\n",
        "      #  Avoid self-loops\n",
        "      if i != j:\n",
        "        # Add directed edge with probability p\n",
        "        if random.random() < p:\n",
        "          diG.add_edge(i, j)\n",
        "\n",
        "  return diG\n",
        "\n",
        "diG = directed_gilbert(10, 0.4)\n",
        "nx.draw(diG, with_labels=True, node_color='lightgreen', node_size=500, font_size=10, font_color='black', pos=nx.spring_layout(G))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9pihei2-Aim"
      },
      "source": [
        "# MILESTONE 2\n",
        "\n",
        "Create a directed random graph with N = 10 nodes and p = 0.4 using the code from your solution for Milestone 1 b).\n",
        "> *If you did not solve that question, use any function provided by NetworkX library to generate a directed random graph.*  \n",
        "\n",
        "a) Compute the following centrality metrics: <Indegree, Outdegree, Closeness, Betweenness, PageRank> using the NetworkX functions with the same name. Print the obtained results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsfGOQZw_pZf"
      },
      "outputs": [],
      "source": [
        "# Solution Milestone 2, question a)\n",
        "num_nodes = 10\n",
        "diG = directed_gilbert(num_nodes=10, p=0.4)\n",
        "\n",
        "# Calculate and print the centrality metrics\n",
        "# In-degree centrality\n",
        "indegree_centrality_nx = diG.in_degree()\n",
        "print(\"In-degree Centrality:\", indegree_centrality_nx, \"\\n\")\n",
        "\n",
        "# Out-degree centrality\n",
        "outdegree_centrality_nx = diG.out_degree()\n",
        "print(\"Out-degree Centrality:\", outdegree_centrality_nx, \"\\n\")\n",
        "\n",
        "# Closeness centrality\n",
        "closeness_centrality_nx = nx.closeness_centrality(diG)\n",
        "print(\"Closeness Centrality:\", closeness_centrality_nx, \"\\n\")\n",
        "\n",
        "# Betweenness centrality\n",
        "betweenness_centrality_nx = nx.betweenness_centrality(diG)\n",
        "print(\"Betweenness Centrality:\", betweenness_centrality_nx, \"\\n\")\n",
        "\n",
        "# PageRank\n",
        "pagerank_nx = nx.pagerank(diG)\n",
        "print(\"PageRank:\", pagerank_nx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxNsBwoC_6Fr"
      },
      "source": [
        "Create a directed random graph with N = 10 nodes and p = 0.4 using the code from your solution for Milestone 1 b).\n",
        "> *If you did not solve that question, use any function provided by NetworkX library to generate a directed random graph.*  \n",
        "\n",
        "b) Write a code that computes the Indegree and Outdegree centrality for all nodes in the graph. *Note the code cannot use the function defined for this purpose in the NetworkX library*\n",
        "\n",
        "Print the results of your solution along with the results obtained with the functions of NetworkX library to compute the Indegree and Outdegree centrality. **Note tha both, your solution and NetworkX functions should provide the same results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hlJ3nKkAqwa"
      },
      "outputs": [],
      "source": [
        "# Solution Milestone 2, question b)\n",
        "# 1º) Initialize dictionaries\n",
        "indegree_centrality = {key: 0 for key in range(num_nodes)}\n",
        "outdegree_centrality = {key: 0 for key in range(num_nodes)}\n",
        "a = [(node, 0) for node in diG]\n",
        "\n",
        "# 2º) Calculate in-degree and out-degree for each node\n",
        "for node in diG:\n",
        "  # We go through the list of edges\n",
        "  for edge in diG.edges():\n",
        "    # in-degree: check how many times node is in 2º position (,node)\n",
        "    if edge[1] == node:\n",
        "      indegree_centrality[node] += 1\n",
        "\n",
        "    # out-degree: check how many times node is in 1º position (node,)\n",
        "    if edge[0] == node:\n",
        "      outdegree_centrality[node] += 1\n",
        "\n",
        "print('In-degree Centrality from nx: ',indegree_centrality_nx)\n",
        "print('In-degree Centrality: ', indegree_centrality)\n",
        "\n",
        "print('Out-degree Centrality from nx: ', outdegree_centrality_nx)\n",
        "print('Out-degree Centrality: ', outdegree_centrality)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UAyyyw7A-TU"
      },
      "source": [
        "Create a directed random graph with N = 10 nodes and p = 0.4 using the code from your solution for Milestone 1 b).\n",
        "> *If you did not solve that question, use any function provided by NetworkX library to generate a directed random graph.*  \n",
        "\n",
        "c) Write a code that computes the Closseness centrality for all nodes in the graph. *Note the code cannot use the function defined for this purpose in the NetworkX library*\n",
        "\n",
        "Print the results of your solution along with the results obtained with the functions of NetworkX library to compute the Closseness centrality. **Note tha both, your solution and NetworkX functions should provide the same results**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Closeness Centrality Formula**\n",
        "\n",
        "The closeness centrality for a node \\( u \\) based on the distances from all other nodes \\( v \\) to \\( u \\) is defined as:\n",
        "\n",
        "$$\n",
        "C(u) = \\frac{n - 1}{\\sum_{v \\neq u} d(v, u)}\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- \\( n \\) is the total number of nodes in the graph,\n",
        "- \\( d(v, u) \\) is the shortest path distance from node \\( v \\) to node \\( u \\),\n",
        "\n"
      ],
      "metadata": {
        "id": "xZImHwylyu7j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tygU9Qe2BQ_u"
      },
      "outputs": [],
      "source": [
        "# Solution Milestone 2, question c)\n",
        "\n",
        "# Reverse the directed graph to compute distances to each node\n",
        "reversed_diG = diG.reverse(copy=True)\n",
        "\n",
        "# Initialize a dictionary to store closeness centrality for each node\n",
        "closeness_centrality = {key: 0 for key in range(num_nodes)}\n",
        "\n",
        "for node in reversed_diG:\n",
        "  # Returns a disctionary with: shortest path lengths to node in the original graph.\n",
        "  path_lengths = nx.single_source_shortest_path_length(reversed_diG, node)\n",
        "  sum_distance = sum(path_lengths.values())\n",
        "\n",
        "  # Check that the current node is not an isolated node to avoid divide by 0\n",
        "  if sum_distance > 0:\n",
        "    # Apply formula\n",
        "    closeness_centrality[node] = (num_nodes - 1)/ sum_distance\n",
        "\n",
        "print('Closeness Centrality from nx: ', closeness_centrality_nx)\n",
        "print('Closeness Centrality: ', closeness_centrality)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4io7XUbCgTx"
      },
      "source": [
        "Create a directed random graph with N = 10 nodes and p = 0.4 using the code from your solution for Milestone 1 b).\n",
        "> *If you did not solve that question, use any function provided by NetworkX library to generate a directed random graph.*  \n",
        "\n",
        "d) Write a code that computes the Betweenness centrality for all nodes in the graph. *Note the code cannot use the function defined for this purpose in the NetworkX library*\n",
        "\n",
        "Print the results of your solution along with the results obtained with the functions of NetworkX library to compute the Betweenness centrality. **Note tha both, your solution and NetworkX functions should provide the same results**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Betweenness Centrality (g)** measures the extent to which a node \\( v \\) lies on the shortest paths between pairs of other nodes in the network. It is defined as:\n",
        "\n",
        "$$\n",
        "g(v) = \\sum_{s \\neq v \\neq t} \\frac{\\sigma_{st}(v)}{\\sigma_{st}}\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- \\( \\sigma_{st}(v) \\) is the number of shortest paths between nodes \\( s \\) and \\( t \\) that pass through node \\( v \\),\n",
        "- \\( \\sigma_{st} \\) is the total number of shortest paths between nodes \\( s \\) and \\( t \\),\n",
        "\n"
      ],
      "metadata": {
        "id": "QaLE9BIP6JQE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6XNe1tFCyIM"
      },
      "outputs": [],
      "source": [
        "# Solution Milestone 2, question d)\n",
        "\n",
        "# Initialize the betweenness centrality dictionary for each node\n",
        "betweenness_centrality  = {key: 0 for key in range(num_nodes)}\n",
        "\n",
        "# Iterate through all nodes and pairs of nodes (s, t) to calculate betweenness centrality\n",
        "for v in diG:  # v: node whose betweenness centrality we are calculating\n",
        "  for s in diG:  # s: source node\n",
        "    for t in diG:  # t: target code\n",
        "      if s != t:  # Skip if s == t, because a node cannot be between itself\n",
        "        try:\n",
        "          # 1º) Obtain a list with the shortest paths from node \"s\" to \"t\"\n",
        "          all_paths_st = list(nx.all_shortest_paths(diG, source=s, target=t))\n",
        "          sigma_st = len(all_paths_st) # total nº of shortest paths between nodes s-t\n",
        "\n",
        "          # 2º) For each shortest path, check if node \"v\" in the path and update closeness\n",
        "          sigma_st_v = 0\n",
        "          for path in all_paths_st:\n",
        "            # Ensure that \"v\" is an intermediary node (not s or t)\n",
        "            if v in path[1:-1]:\n",
        "                sigma_st_v += 1\n",
        "\n",
        "          # Update the betweenness centrality for node \"v\"\n",
        "          if sigma_st > 0:  # Avoid division by zero\n",
        "              betweenness_centrality[v] += sigma_st_v / sigma_st\n",
        "\n",
        "        except nx.NetworkXNoPath:\n",
        "          # If no path exists, skip to the next pair of nodes\n",
        "          continue\n",
        "\n",
        "  # Normalize the betweenness centrality for each node\n",
        "  betweenness_centrality [v] /= ((num_nodes - 1)*(num_nodes -2))\n",
        "\n",
        "print('Betweenness Centrality from nx:', betweenness_centrality_nx)\n",
        "print('Betweenness Centrality:', betweenness_centrality )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6SaAJFoDCQQ"
      },
      "source": [
        "Create a directed random graph with N = 10 nodes and p = 0.4 using the code from your solution for Milestone 1 b).\n",
        "> *If you did not solve that question, use any function provided by NetworkX library to generate a directed random graph.*  \n",
        "\n",
        "d) Write a code that computes the Pagerank for all nodes in the graph. *Note the code cannot use the function defined for this purpose in the NetworkX library*\n",
        "> Use a stop condition such that the sum of the Pagerank value of of all nodes in the graph for iteration i is < 10^-5 compared to iteration i-1.\n",
        "\n",
        "Print the results of your solution along with the results obtained with the functions of NetworkX library to compute the Pagerank. **Note that both, your solution and NetworkX functions should provide the same results.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution Milestone 2, question e)\n",
        "\n",
        "epsilon = 1e-5  # Convergence threshold\n",
        "d = 0.85  # Damping factor\n",
        "\n",
        "# Initialize PR with equal values for all nodes (1/N)\n",
        "pagerank = {node: 1/num_nodes for node in diG.nodes()}\n",
        "\n",
        "convergence = False\n",
        "while not convergence:\n",
        "    temp_pr = {}\n",
        "\n",
        "    # For each node compute the new PR value\n",
        "    for node in diG:\n",
        "        pr_node = (1 - d) / num_nodes  # Base contribution\n",
        "\n",
        "        # Sum the contributions from all incoming neighbors\n",
        "        for in_node, _ in diG.in_edges(node):  # Iterate over incoming edges\n",
        "            if diG.out_degree(in_node) > 0:  # Avoid division by zero\n",
        "                pr_node += d * pagerank[in_node] / diG.out_degree(in_node)  # Contribution from in-neighbors\n",
        "\n",
        "        # Store the new PageRank value for this node\n",
        "        temp_pr[node] = pr_node\n",
        "\n",
        "    # Check convergence based on the sum of absolute differences (L1 norm)\n",
        "    diff_sum = sum(abs(temp_pr[node] - pagerank[node]) for node in diG)\n",
        "\n",
        "    # Update the pagerank values with the new computed values\n",
        "    pagerank = temp_pr\n",
        "\n",
        "    # If the sum of differences is smaller than epsilon, we consider the algorithm to have converged\n",
        "    if diff_sum < epsilon:\n",
        "        convergence = True\n",
        "\n",
        "print('Pagerank from nx: ', pagerank_nx)\n",
        "print('Computed Pagerank: ', pagerank)"
      ],
      "metadata": {
        "id": "pgmMdQ6GXD_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNqhwUetF8ym"
      },
      "source": [
        "# MILESTONE 3\n",
        "Create an undirected random graph with N = 10 nodes and p = 0.4 using the code from your solution for Milestone 1 b).\n",
        "> *If you did not solve that question, use any function provided by NetworkX library to generate an undirected random graph.*  \n",
        "\n",
        "a) Write a code that  implements the k-core decomposition of a graph. The code should provide the k-core and the layer for each node in the graph. *Note the code cannot use the function defined for this purpose in the NetworkX library*\n",
        "\n",
        "Print the results of your solution along with the results obtained with the functions of NetworkX library to compute the k-core (```core_number```) and layer (```onion_layers```). **Note that both, your solution and NetworkX functions should provide the same results**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create requested graph\n",
        "G = undirected_gilbert(10, 0.4)\n",
        "nx.draw(G, with_labels=True, node_color='lightgreen', node_size=500, font_size=10, font_color='black', pos=nx.spring_layout(G))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oVoRGoVYnc3y",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPeNIOxtHgs_"
      },
      "outputs": [],
      "source": [
        "# Solution Milestone 3\n",
        "def k_core_decomposition(G):\n",
        "  # Make a copy to avoid modifying the original graph\n",
        "  G = G.copy()\n",
        "\n",
        "  # Initialize dictionaries to store core numbers and onion layers for each node\n",
        "  core_numbers = {}\n",
        "  onion_layers = {}\n",
        "\n",
        "  k = 0  # To keep track of the minimum degree in the k-core decomposition\n",
        "  layer = 1  # To track the current layer\n",
        "\n",
        "  # Loop until all nodes are removed from the graph\n",
        "  while G.number_of_nodes() > 0:\n",
        "    degrees = G.degree()  # Get the degree of all nodes\n",
        "    min_deg = min(dict(degrees).values())  # Find the minimum degree among the remaining nodes\n",
        "\n",
        "    # Update k to be the maximum of the current core number and minimum degree\n",
        "    k = max(k, min_deg)\n",
        "\n",
        "    # Identify nodes that have a degree <= k\n",
        "    removing_nodes = [node for (node, deg) in degrees if deg <= k]\n",
        "\n",
        "    # For each node to be removed, assign its core number and onion layer\n",
        "    for node in removing_nodes:\n",
        "      core_numbers[node] = k\n",
        "      onion_layers[node] = layer\n",
        "\n",
        "    # If there are nodes to remove, update the graph my removing them\n",
        "    if removing_nodes:\n",
        "      G.remove_nodes_from(removing_nodes)\n",
        "      layer += 1\n",
        "\n",
        "  return core_numbers, onion_layers\n",
        "\n",
        "our_core_numbers, our_onion_layers = k_core_decomposition(G)\n",
        "print(\"Core Numbers:\", our_core_numbers)\n",
        "print(\"Onion Layers:\", our_onion_layers)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NetworkX function comparison\n",
        "nx_core_numbers = nx.core_number(G)\n",
        "nx_onion_layers = nx.onion_layers(G)\n",
        "\n",
        "print(\"Core Numbers:\", nx_core_numbers)\n",
        "print(\"Onion Layers:\", nx_onion_layers)"
      ],
      "metadata": {
        "id": "993ja7Zvc_kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert nx_core_numbers == our_core_numbers, \"K-core numbers not equal to NetworkX implementation\"\n",
        "assert nx_onion_layers == our_onion_layers, \"Onion layers not equal to NetworkX implementation\""
      ],
      "metadata": {
        "id": "LcOOJtvYnPIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NwrqGo-H2ai"
      },
      "source": [
        "# MILESTONE 4\n",
        "\n",
        "a) Write a code that computes the modularity giving a Graph and the communities within that graph.\n",
        "\n",
        "Consider the following predefined graphs available in the NetworkX library: karate_club_graph, davis_southern_women_graph, florentine_families_graph and les_miserables_graph.\n",
        "\n",
        "For each of these graphs compute the existing communities using the following community detection algorithms available in NetworkX:\n",
        "*  ```label_propagation_communities``` (you have to ``` import networkx.algorithms.community```).\n",
        "* ```greedy_modularity_communities``` (you have to ```import networkx.algorithms.community```).\n",
        "* ```community_louvain.best_partition``` (you have to ``` import from community import community_louvain```).\n",
        "\n",
        "b) For each of the 4 predefined graphs compute the resulting modularity and execution time of each of the 3 considered community detection algorithms. Print the results of the two metrics.\n",
        "\n",
        "c) Which is the best algorithms based on the modularity and execution time metrics?\n",
        "\n",
        "\n",
        "**Note that you can validate your code to compute modularity is correct by comparing the obtained results with those provided by the modularity function offered by the NetworkX library: ```modularity```(you have to ```import networkx.algorithms.community```).**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6bBGkeCKJcZ"
      },
      "outputs": [],
      "source": [
        "# Solution Milestone 4\n",
        "# A) Write a code that computes the modularity giving a Graph and the communities within that graph\n",
        "import time\n",
        "from community import community_louvain\n",
        "from networkx.algorithms import community\n",
        "from networkx.algorithms.community.quality import modularity as nx_modularity\n",
        "\n",
        "def compute_modularity(graph, communities):\n",
        "    # Manual computation of the modularity for a given partition of communities in a graph\n",
        "    # using the formula for modularity Q\n",
        "\n",
        "    # Total number of edges\n",
        "    m = graph.number_of_edges()\n",
        "    modularity = 0.0\n",
        "\n",
        "    # Node-community assignment (c_i and c_j)\n",
        "    node_to_comm = {}\n",
        "    for i, community in enumerate(communities):\n",
        "        for node in community:\n",
        "            node_to_comm[node] = i\n",
        "\n",
        "    # Compute modularity\n",
        "    for u in graph.nodes():\n",
        "        for v in graph.nodes():\n",
        "            # Check if there is an edge between u and v\n",
        "            A_uv = 1 if graph.has_edge(u, v) else 0\n",
        "            k_u = graph.degree[u]\n",
        "            k_v = graph.degree[v]\n",
        "            if node_to_comm[u] == node_to_comm[v]:  # Nodes in the same community\n",
        "                modularity += (A_uv - (k_u * k_v) / (2 * m))\n",
        "    modularity /= (2*m)\n",
        "\n",
        "    return modularity\n",
        "\n",
        "graphs = {\n",
        "    \"karate_club_graph\": nx.karate_club_graph(),\n",
        "    \"davis_southern_women_graph\": nx.davis_southern_women_graph(),\n",
        "    \"florentine_families_graph\": nx.florentine_families_graph(),\n",
        "    \"les_miserables_graph\": nx.les_miserables_graph()\n",
        "}\n",
        "\n",
        "algorithms = [\"label_propagation\", \"greedy_modularity\", \"community_louvain\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# B) For each of the 4 predefined graphs compute the resulting modularity and\n",
        "# execution time of each of the 3 considered community detection algorithms.\n",
        "# Print the results of the two metrics\n",
        "def evaluate_community_detection(graph, algorithm_name):\n",
        "    start_time = time.time()\n",
        "    if algorithm_name == \"label_propagation\":\n",
        "        communities = list(community.label_propagation_communities(graph))\n",
        "    elif algorithm_name == \"greedy_modularity\":\n",
        "        communities = list(community.greedy_modularity_communities(graph))\n",
        "    elif algorithm_name == \"community_louvain\":\n",
        "        # In the case of the Louvain algorithm, the function returns a dictionary (partition),\n",
        "        # where each key is a node in the graph and each value is the community ID assigned to\n",
        "        # that node by the Louvain algorihtm\n",
        "        partition = community_louvain.best_partition(graph)\n",
        "\n",
        "        # To make the partition compatible with the modularity calculation, the dictionary\n",
        "        # must be converted into a list of sets, each representing a community containing\n",
        "        # nodes grouped by the community IDs\n",
        "        communities = [set() for _ in range(max(partition.values()) + 1)]\n",
        "        for node, comm in partition.items():\n",
        "            communities[comm].add(node)\n",
        "\n",
        "    modularity_score = compute_modularity(graph, communities)\n",
        "    execution_time = time.time() - start_time\n",
        "    nx_modularity_score = nx_modularity(graph, communities)\n",
        "\n",
        "    return modularity_score, nx_modularity_score, execution_time, communities\n",
        "\n",
        "# Run each algorithm on each graph and store results\n",
        "results = {}\n",
        "for graph_name, graph in graphs.items():\n",
        "    results[graph_name] = {}\n",
        "    for algorithm in algorithms:\n",
        "        modularity, nx_modularity_score, execution_time, communities = evaluate_community_detection(graph, algorithm)\n",
        "        results[graph_name][algorithm] = {\n",
        "            \"modularity\": modularity,\n",
        "            \"nx_modularity\": nx_modularity_score,\n",
        "            \"execution_time\": execution_time,\n",
        "            \"communities\": communities\n",
        "        }\n",
        "        print(f\"Graph: {graph_name}, Algorithm: {algorithm}\")\n",
        "        print(f\"Modularity: {modularity:.4f}\")\n",
        "        print(f\"NX Modularity: {nx_modularity_score:.4f}\")\n",
        "        print(f\"Execution Time: {execution_time:.4f} seconds\\n\")"
      ],
      "metadata": {
        "id": "YzY5ASAfB_Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C) Which is the best algorithms based on the modularity and execution time metrics?\n",
        "best_algorithm = {}\n",
        "for graph_name, algorithms_data in results.items():\n",
        "    best_modularity = max(algorithms_data, key=lambda x: algorithms_data[x][\"modularity\"])\n",
        "    best_time = min(algorithms_data, key=lambda x: algorithms_data[x][\"execution_time\"])\n",
        "\n",
        "    best_algorithm[graph_name] = {\n",
        "        \"highest_modularity_algorithm\": best_modularity,\n",
        "        \"highest_modularity_score\": algorithms_data[best_modularity][\"modularity\"],\n",
        "        \"fastest_algorithm\": best_time,\n",
        "        \"fastest_execution_time\": algorithms_data[best_time][\"execution_time\"]\n",
        "    }\n",
        "\n",
        "print(\"\\nBest Algorithm by Graph Based on Modularity and Execution Time:\")\n",
        "for graph_name, best_info in best_algorithm.items():\n",
        "    print(f\"Graph: {graph_name}\")\n",
        "    print(f\"  Highest Modularity Algorithm: {best_info['highest_modularity_algorithm']}, Modularity Score: {best_info['highest_modularity_score']:.4f}\")\n",
        "    print(f\"  Fastest Algorithm: {best_info['fastest_algorithm']}, Execution Time: {best_info['fastest_execution_time']:.4f} seconds\\n\")"
      ],
      "metadata": {
        "id": "vO20nz0XIDS6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fNNnpecv1wbt"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}