{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"afwfMTuQT2O0"},"source":["<img src=\"https://www.uc3m.es/ss/Satellite?blobcol=urldata&blobkey=id&blobtable=MungoBlobs&blobwhere=1371573952659\">\n","\n","---\n","\n","# WEB ANALYTICS COURSE 4 - SEMESTER 2\n","# BACHELOR IN DATA SCIENCE AND ENGINEERING\n","\n","# LAB 1.1 WEB SCRAPING WITH BEAUTIFULSOUP\n","\n","---\n"]},{"cell_type":"markdown","source":["## Group Members\n","* Ángela María Durán Pinto: 100472766\n","* Alejandro Leonardo García Navarro: 100472710\n","* Melania Guerra Ulloa: 100457522\n","* Francisco Javier Molina Tirado: 100456560"],"metadata":{"id":"thFnoRTbGjKi"}},{"cell_type":"markdown","metadata":{"id":"0NeV05Oml2dF"},"source":["# 0. Lab Preparation\n","\n","1.  Study and have clear the concepts explained in the theoretical class and the introductory lab.\n","\n","2.   Gain experience with the use of the [Requests](https://docs.python-requests.org/en/master/) and [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/). The exercises of this lab will be mainly based on the utilization of functions offered by these libraries.\n","\n","3. It is assumed students have experience in using Python notebooks. Either a local installation (e.g., local python installation + Jupyter) or a cloud-based solution (e.g., Google Colab). *We recommend the second option*."]},{"cell_type":"markdown","metadata":{"id":"o7WfODWPm67o"},"source":["# 1. Lab Introduction\n"]},{"cell_type":"markdown","metadata":{"id":"MMRIv1eekgK0"},"source":["* In this lab, we will implement a web scraper using the parsing library [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/). One of the tools explained in the theoretical class.\n","\n","* The lab will be done in groups of 4 people.\n","\n","* The lab defines a set of milestones the students must complete. Upon completing every milestone, students should call the professor, who will check the correctness of the solution (*If the professor is busy, do not wait for them, move to the next milestone*).\n","\n","* **The final mark will be computed as a function of the number of milestones successfully completed.**\n","\n","* **Each group should also share their lab notebook with the professor upon the finalization of the lab.**\n","\n","* In this lab we will use the [Requests](https://docs.python-requests.org/en/master/) and [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) libraries for the creation of a web scraper, to extract information from the web. As indicated in the *Lab Preparation* section above, it is expected that students have gained experience in the use of the libraries before starting the first session of the lab.\n","\n","- It is recommended to use [Google Colab](https://colab.research.google.com/) to produce the Python notebook with the solution of the lab. Of course, if any student prefers using its local programming environment (e.g., jupyter) and python installation, they are welcome to do so."]},{"cell_type":"markdown","metadata":{"id":"9_W-5JKjoiDb"},"source":["# MILESTONE 1\n","\n","a) Access to the website [BACHELOR IN DATA SCIENCE AND ENGINEERING\n","](https://www.uc3m.es/bachelor-degree/data-science)\n","\n","b) Create the _BeautifulSoup_ object.\n","\n","c) Find the element tag with `id=\"quality\"` and print the result.\n","\n","d) Find the `Places offered:` inside QUALITY and print the result.\n"]},{"cell_type":"code","source":["# Import necessary libraries\n","import requests\n","from bs4 import BeautifulSoup"],"metadata":{"id":"z2C5-n7ofhg2"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"et_kjc37yycj"},"source":["## A) Access to the website BACHELOR IN DATA SCIENCE AND ENGINEERING\n","# Define the URL of the website we want to access\n","web_url = \"https://www.uc3m.es/bachelor-degree/data-science\"\n","\n","# Sends a GET request to the specified url\n","page = requests.get(web_url)\n","\n","## B) Create the BeautifulSoup object\n","soup = BeautifulSoup(page.content, \"html.parser\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RJbMg_xfy9D8"},"source":["## C) Find the element tag with id=\"quality\" and print the result\n","quality_title = soup.find(id=\"quality\")\n","print(quality_title.prettify())"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## D) Find the \"Places offered:\" inside QUALITY and print the result.\n","# Inspect the element tag using parent.parent. With this, we get to the container of the QUALITY section, and find the element with text \"Places offered:\"\n","quality_title.parent.parent"],"metadata":{"id":"LF4mT6BN3vhC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print the result\n","print(quality_title.parent.parent.find(string=\"Places offered:\"))"],"metadata":{"id":"E92IJqSbiIBy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MfJJ5jXioaeA"},"source":["# MILESTONE 2\n","\n","a) Obtain the link to Web Analytics course (see inside Program) by finding the corresponding href with _BeautifulSoup_.\n","\n","b) Access to this URL and create a new _BeautifulSoup_ object.\n","\n","c) Print the text inside the Objectives section.\n"]},{"cell_type":"code","metadata":{"id":"QSp3Zrq2b_-M","collapsed":true},"source":["## A) Obtain the link to Web Analytics course (see inside Program) by finding the corresponding href with BeautifulSoup\n","# Find the Program section\n","program_title = soup.find(id=\"program\")\n","program_section = program_title.parent.parent\n","\n","# Find the course \"Web Analytics\" inside Program\n","web_analytics_container = program_section.find(string=\"Web Analytics\").parent.parent\n","web_analytics_container"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U8UG5eP4b_6V"},"source":["# Get the URL\n","wa_url = web_analytics_container.get(\"href\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## B) Access to this URL and create a new BeautifulSoup object\n","page2 = requests.get(wa_url)\n","soup2 = BeautifulSoup(page2.content, \"html.parser\")"],"metadata":{"id":"kgBRFW0C4pJH"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xNMexjQxb_11"},"source":["## C) Print the text inside the Objectives section\n","soup2.find(string=\"Objectives\").parent.find_next_sibling().text"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LvWXdKNY23Yw"},"source":["# MILESTONE 3\n","\n","Now let's build the first steps for a price monitoring website. For that, we are going to use yamovil.com to obtain car prices. Specifically, we want to find SEAT cars in Madrid and the price of each of them.\n","\n","Follow these steps:\n","\n","a) Check https://www.yamovil.es/robots.txt and see if the site can be crawled or not for our specific search. Explain.\n","\n","b) If yes, use this [URL](https://www.yamovil.es/coches-segunda-mano/seat-ocasion-en-madrid) which already includes the indicated search (SEAT Cars Madrid Second Hand), scrape the HTML using _BeautifulSoup_, and print the **mark**, **model**, **version** and **price** of each available car.\n","\n","**HINT:** The resulting list should have 30 cars (which are the ones that appear in the first page)\n"]},{"cell_type":"markdown","source":["**A) Check https://www.yamovil.es/robots.txt and see if the site can be crawled or not for our specific search. Explain.**\n","\n","After checking the `robots.txt` link, we can see that it disallows any spiders from crawling the following sublinks of the page:\n","- `/admin/`\n","- `/feed/`\n","- `/goal/`\n","- `/sobre-coches-y-concesionarios/ category/`\n","- `/sobre-coches-y-concesionarios/ articulos/`\n","- `/sobre-coches-y-concesionarios/ author/`\n","\n","However, since the page we are going to crawl is https://www.yamovil.es/coches-segunda-mano/seat-ocasion-en-madrid, it does not prohibit us from crawling it."],"metadata":{"id":"vhkq7kXlpXGQ"}},{"cell_type":"code","metadata":{"id":"wZ8GKqx9DH6h","collapsed":true},"source":["## B) If yes, use this URL which already includes the indicated search (SEAT Cars Madrid Second Hand),\n","## scrape the HTML using BeautifulSoup, and print the mark, model, version and price of each available car.\n","# Access the indicated URL\n","yamovil_url = \"https://www.yamovil.es/coches-segunda-mano/seat-ocasion-en-madrid\"\n","page3 = requests.get(yamovil_url)\n","\n","# Create the BeautifulSoup object\n","soup3 = BeautifulSoup(page3.content, \"html.parser\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UvC5-azycBkh"},"source":["# Find all the cars available in the page\n","all_cars = soup3.find(class_=\"vehicle-list\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FyKkKXzwcBht"},"source":["# Print the mark, model, version and price of each available car\n","for i, car_item in enumerate(all_cars.find_all(class_=\"vehicle-list__item\")):\n","  print(f\"- Car #{i+1}:\")\n","  print(\"Mark: \", car_item.find(class_=\"make\").text)\n","  print(\"Model: \", car_item.find(class_=\"model\").text)\n","  print(\"Version: \", car_item.find(class_=\"version\").text)\n","  print(\"Price: \", car_item.find(class_=\"price\").text)\n","  print(\"\\n\")"],"execution_count":null,"outputs":[]}]}